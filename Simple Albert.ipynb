{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Albert\n",
    "\n",
    "Implementaion of ALBERT is taken from Hugging Face library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import json\n",
    "import pandas as pd\n",
    "from squad import Squad\n",
    "\n",
    "from transformers import (\n",
    "    AlbertConfig,\n",
    "    AlbertModel,\n",
    "    AlbertTokenizer,\n",
    "    squad_convert_examples_to_features\n",
    ")\n",
    "\n",
    "from transformers.data.processors.squad import SquadResult, SquadV2Processor, SquadExample\n",
    "from transformers.data.metrics.squad_metrics import compute_predictions_logits, get_final_text\n",
    "from evaluate_answers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"\"\n",
    "do_lower_case = True\n",
    "\n",
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist() \n",
    "\n",
    "# Tokenizer for ALBERT's input format\n",
    "tokenizer_class = AlbertTokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(\n",
    "    \"albert-base-v2\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and test dataframes\n",
    "train_sq = Squad(\"./data/train-v2.0.json\")\n",
    "test_sq = Squad(\"./data/dev-v2.0.json\")\n",
    "train_df = train_sq.get_dataframe()\n",
    "test_df = test_sq.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_dataset(train_df, tokenizer):\n",
    "    \"\"\"\n",
    "    Create dataset from DataFrame\n",
    "    \n",
    "    returns: \n",
    "        dataset - pytorch dataset of training data features\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    for i, question in enumerate(train_df['content']):\n",
    "        example = SquadExample(\n",
    "            qas_id=str(i),\n",
    "            question_text=question,\n",
    "            context_text=train_df['context'][i],\n",
    "            answer_text=train_df['answer'][i],\n",
    "            start_position_character=train_df['answer_start'][i],\n",
    "            title=\"Train\",\n",
    "            is_impossible=False,\n",
    "            answers=None,\n",
    "        )\n",
    "        examples.append(example)\n",
    "    \n",
    "    features, dataset = squad_convert_examples_to_features(\n",
    "        examples=examples,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=384,\n",
    "        doc_stride=128,\n",
    "        max_query_length=64,\n",
    "        is_training=True,\n",
    "        return_dataset=\"pt\",\n",
    "        threads=32,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return dataset, features, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 130319/130319 [01:55<00:00, 1128.32it/s]\n",
      "add example index and unique id: 100%|██████████| 130319/130319 [00:00<00:00, 606754.82it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset, _, _ = create_train_dataset(train_df, tokenizer)\n",
    "\n",
    "train_sampler = SequentialSampler(dataset)\n",
    "train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer4QA(nn.Module):\n",
    "    def __init__(self, freeze_albert = True):\n",
    "        super(Transformer4QA, self).__init__()\n",
    "        # create model's config\n",
    "        config_class, model_class = (AlbertConfig, AlbertModel)\n",
    "        config = config_class.from_pretrained(\"albert-base-v2\")\n",
    "        config.output_hidden_states=True\n",
    "        self.backbone = model_class.from_pretrained(\"albert-base-v2\", config=config)\n",
    "        \n",
    "        # freeze ALBERT layers if freeze_albert is True\n",
    "        if freeze_albert:\n",
    "            for param in self.backbone.embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            for param in self.backbone.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            for param in self.backbone.pooler.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            for param in self.backbone.pooler_activation.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.QA = nn.Sequential(\n",
    "            nn.Linear(768,2)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, batch, device='cpu'):\n",
    "        # inference through ALBERT\n",
    "        self.backbone.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2],\n",
    "            }\n",
    "\n",
    "            features, _, _ = self.backbone(**inputs)\n",
    "        \n",
    "        logits = self.QA(features)\n",
    "        \n",
    "        # get start and end logits also calculate loss\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1).squeeze(1)\n",
    "        end_logits = end_logits.squeeze(-1).squeeze(1)\n",
    "        \n",
    "        start_positions = batch[3]\n",
    "        end_positions = batch[4]\n",
    "        \n",
    "        \n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions.clamp_(0, ignored_index)\n",
    "            end_positions.clamp_(0, ignored_index)\n",
    "\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=ignored_index)\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss)/2\n",
    "        return total_loss, start_logits, end_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelA = Transformer4QA(freeze_albert=True).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(modelA.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, optimizer):\n",
    "    model.zero_grad()\n",
    "    f = open(\"logs.txt\", \"w\")\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            model_loss ,start_logits, end_logits = model(batch,device=device)\n",
    "            loss += model_loss.item()          \n",
    "            \n",
    "            model_loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            \n",
    "            if idx % 100 == 0:\n",
    "                start_pred = torch.argmax(start_logits, dim=1).cpu()\n",
    "                end_pred = torch.argmax(end_logits, dim=1).cpu()\n",
    "                pair_accuracy = ((start_pred==batch[3])*(end_pred==batch[4])).sum().float() / len(batch[3])\n",
    "                start_accuracy = (start_pred==batch[3]).sum().float() / len(batch[3])\n",
    "                end_accuracy = (end_pred==batch[4]).sum().float() / len(batch[4])\n",
    "                string = f\"[{idx+1}/{len(train_dataloader)}]Epoch: {epoch+1}/{epochs} Loss: {model_loss.item()} Pair Accuracy: {pair_accuracy} Start Accuracy: {start_accuracy} End Accuracy: {end_accuracy}\"\n",
    "                print(string)\n",
    "                f.write(string)\n",
    "                torch.save(model.state_dict(), \"albert.pth\")\n",
    "    f.close()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/4132]Epoch: 1/2 Loss: 6.05572509765625 Pair Accuracy: 0.0 Start Accuracy: 0.0 End Accuracy: 0.0\n",
      "[101/4132]Epoch: 1/2 Loss: 3.359996795654297 Pair Accuracy: 0.0625 Start Accuracy: 0.25 End Accuracy: 0.15625\n",
      "[201/4132]Epoch: 1/2 Loss: 2.316701889038086 Pair Accuracy: 0.09375 Start Accuracy: 0.40625 End Accuracy: 0.3125\n",
      "[301/4132]Epoch: 1/2 Loss: 3.0504703521728516 Pair Accuracy: 0.34375 Start Accuracy: 0.34375 End Accuracy: 0.5\n",
      "[401/4132]Epoch: 1/2 Loss: 3.8048295974731445 Pair Accuracy: 0.09375 Start Accuracy: 0.15625 End Accuracy: 0.34375\n",
      "[501/4132]Epoch: 1/2 Loss: 3.7506325244903564 Pair Accuracy: 0.03125 Start Accuracy: 0.09375 End Accuracy: 0.0625\n",
      "[601/4132]Epoch: 1/2 Loss: 3.5632386207580566 Pair Accuracy: 0.0625 Start Accuracy: 0.0625 End Accuracy: 0.28125\n",
      "[701/4132]Epoch: 1/2 Loss: 2.8157577514648438 Pair Accuracy: 0.03125 Start Accuracy: 0.3125 End Accuracy: 0.15625\n",
      "[801/4132]Epoch: 1/2 Loss: 2.004009485244751 Pair Accuracy: 0.3125 Start Accuracy: 0.5625 End Accuracy: 0.46875\n",
      "[901/4132]Epoch: 1/2 Loss: 2.9666619300842285 Pair Accuracy: 0.0625 Start Accuracy: 0.15625 End Accuracy: 0.21875\n",
      "[1001/4132]Epoch: 1/2 Loss: 2.6651816368103027 Pair Accuracy: 0.125 Start Accuracy: 0.25 End Accuracy: 0.40625\n",
      "[1101/4132]Epoch: 1/2 Loss: 1.9428691864013672 Pair Accuracy: 0.46875 Start Accuracy: 0.625 End Accuracy: 0.53125\n",
      "[1201/4132]Epoch: 1/2 Loss: 3.01242733001709 Pair Accuracy: 0.3125 Start Accuracy: 0.34375 End Accuracy: 0.46875\n",
      "[1301/4132]Epoch: 1/2 Loss: 3.2170422077178955 Pair Accuracy: 0.0625 Start Accuracy: 0.1875 End Accuracy: 0.15625\n",
      "[1401/4132]Epoch: 1/2 Loss: 2.622377872467041 Pair Accuracy: 0.1875 Start Accuracy: 0.21875 End Accuracy: 0.4375\n",
      "[1501/4132]Epoch: 1/2 Loss: 2.3130292892456055 Pair Accuracy: 0.40625 Start Accuracy: 0.4375 End Accuracy: 0.5\n",
      "[1601/4132]Epoch: 1/2 Loss: 2.5546157360076904 Pair Accuracy: 0.125 Start Accuracy: 0.34375 End Accuracy: 0.1875\n",
      "[1701/4132]Epoch: 1/2 Loss: 3.2436203956604004 Pair Accuracy: 0.09375 Start Accuracy: 0.15625 End Accuracy: 0.28125\n",
      "[1801/4132]Epoch: 1/2 Loss: 2.368062734603882 Pair Accuracy: 0.25 Start Accuracy: 0.34375 End Accuracy: 0.5\n",
      "[1901/4132]Epoch: 1/2 Loss: 2.2154507637023926 Pair Accuracy: 0.21875 Start Accuracy: 0.34375 End Accuracy: 0.4375\n",
      "[2001/4132]Epoch: 1/2 Loss: 2.22224760055542 Pair Accuracy: 0.53125 Start Accuracy: 0.53125 End Accuracy: 0.6875\n",
      "[2101/4132]Epoch: 1/2 Loss: 1.6499539613723755 Pair Accuracy: 0.5 Start Accuracy: 0.53125 End Accuracy: 0.59375\n",
      "[2201/4132]Epoch: 1/2 Loss: 2.439018487930298 Pair Accuracy: 0.3125 Start Accuracy: 0.34375 End Accuracy: 0.59375\n",
      "[2301/4132]Epoch: 1/2 Loss: 2.63102388381958 Pair Accuracy: 0.09375 Start Accuracy: 0.09375 End Accuracy: 0.46875\n",
      "[2401/4132]Epoch: 1/2 Loss: 3.527657985687256 Pair Accuracy: 0.0625 Start Accuracy: 0.1875 End Accuracy: 0.15625\n",
      "[2501/4132]Epoch: 1/2 Loss: 2.6461374759674072 Pair Accuracy: 0.21875 Start Accuracy: 0.34375 End Accuracy: 0.375\n",
      "[2601/4132]Epoch: 1/2 Loss: 2.947631359100342 Pair Accuracy: 0.25 Start Accuracy: 0.25 End Accuracy: 0.5\n",
      "[2701/4132]Epoch: 1/2 Loss: 2.364628791809082 Pair Accuracy: 0.25 Start Accuracy: 0.40625 End Accuracy: 0.46875\n",
      "[2801/4132]Epoch: 1/2 Loss: 2.596780300140381 Pair Accuracy: 0.25 Start Accuracy: 0.34375 End Accuracy: 0.34375\n",
      "[2901/4132]Epoch: 1/2 Loss: 2.694796085357666 Pair Accuracy: 0.25 Start Accuracy: 0.375 End Accuracy: 0.46875\n",
      "[3001/4132]Epoch: 1/2 Loss: 2.3027095794677734 Pair Accuracy: 0.15625 Start Accuracy: 0.1875 End Accuracy: 0.53125\n",
      "[3101/4132]Epoch: 1/2 Loss: 2.3799519538879395 Pair Accuracy: 0.40625 Start Accuracy: 0.4375 End Accuracy: 0.5\n",
      "[3201/4132]Epoch: 1/2 Loss: 3.02874755859375 Pair Accuracy: 0.15625 Start Accuracy: 0.1875 End Accuracy: 0.3125\n",
      "[3301/4132]Epoch: 1/2 Loss: 2.7579169273376465 Pair Accuracy: 0.28125 Start Accuracy: 0.34375 End Accuracy: 0.59375\n",
      "[3401/4132]Epoch: 1/2 Loss: 3.8239011764526367 Pair Accuracy: 0.09375 Start Accuracy: 0.125 End Accuracy: 0.25\n",
      "[3501/4132]Epoch: 1/2 Loss: 3.653008460998535 Pair Accuracy: 0.0 Start Accuracy: 0.0625 End Accuracy: 0.15625\n",
      "[3601/4132]Epoch: 1/2 Loss: 2.622163772583008 Pair Accuracy: 0.15625 Start Accuracy: 0.25 End Accuracy: 0.25\n",
      "[3701/4132]Epoch: 1/2 Loss: 2.0595359802246094 Pair Accuracy: 0.34375 Start Accuracy: 0.5625 End Accuracy: 0.4375\n",
      "[3801/4132]Epoch: 1/2 Loss: 2.9622201919555664 Pair Accuracy: 0.125 Start Accuracy: 0.375 End Accuracy: 0.1875\n",
      "[3901/4132]Epoch: 1/2 Loss: 2.1330370903015137 Pair Accuracy: 0.1875 Start Accuracy: 0.5 End Accuracy: 0.3125\n",
      "[4001/4132]Epoch: 1/2 Loss: 3.478020191192627 Pair Accuracy: 0.03125 Start Accuracy: 0.125 End Accuracy: 0.125\n",
      "[4101/4132]Epoch: 1/2 Loss: 2.6698269844055176 Pair Accuracy: 0.09375 Start Accuracy: 0.15625 End Accuracy: 0.4375\n",
      "[1/4132]Epoch: 2/2 Loss: 3.6619791984558105 Pair Accuracy: 0.0 Start Accuracy: 0.15625 End Accuracy: 0.03125\n",
      "[101/4132]Epoch: 2/2 Loss: 2.869588851928711 Pair Accuracy: 0.0625 Start Accuracy: 0.25 End Accuracy: 0.15625\n",
      "[201/4132]Epoch: 2/2 Loss: 1.975938320159912 Pair Accuracy: 0.15625 Start Accuracy: 0.28125 End Accuracy: 0.46875\n",
      "[301/4132]Epoch: 2/2 Loss: 2.554873466491699 Pair Accuracy: 0.34375 Start Accuracy: 0.34375 End Accuracy: 0.5\n",
      "[401/4132]Epoch: 2/2 Loss: 3.342703342437744 Pair Accuracy: 0.0625 Start Accuracy: 0.125 End Accuracy: 0.28125\n",
      "[501/4132]Epoch: 2/2 Loss: 3.6077303886413574 Pair Accuracy: 0.0625 Start Accuracy: 0.09375 End Accuracy: 0.125\n",
      "[601/4132]Epoch: 2/2 Loss: 3.4051852226257324 Pair Accuracy: 0.0625 Start Accuracy: 0.09375 End Accuracy: 0.25\n",
      "[701/4132]Epoch: 2/2 Loss: 2.5637526512145996 Pair Accuracy: 0.0625 Start Accuracy: 0.3125 End Accuracy: 0.25\n",
      "[801/4132]Epoch: 2/2 Loss: 1.8002040386199951 Pair Accuracy: 0.28125 Start Accuracy: 0.59375 End Accuracy: 0.375\n",
      "[901/4132]Epoch: 2/2 Loss: 2.8239359855651855 Pair Accuracy: 0.0625 Start Accuracy: 0.1875 End Accuracy: 0.25\n",
      "[1001/4132]Epoch: 2/2 Loss: 2.4319894313812256 Pair Accuracy: 0.15625 Start Accuracy: 0.21875 End Accuracy: 0.40625\n",
      "[1101/4132]Epoch: 2/2 Loss: 1.8037240505218506 Pair Accuracy: 0.5 Start Accuracy: 0.65625 End Accuracy: 0.53125\n",
      "[1201/4132]Epoch: 2/2 Loss: 2.995600938796997 Pair Accuracy: 0.28125 Start Accuracy: 0.3125 End Accuracy: 0.5\n",
      "[1301/4132]Epoch: 2/2 Loss: 3.0370121002197266 Pair Accuracy: 0.0625 Start Accuracy: 0.25 End Accuracy: 0.15625\n",
      "[1401/4132]Epoch: 2/2 Loss: 2.5042519569396973 Pair Accuracy: 0.1875 Start Accuracy: 0.25 End Accuracy: 0.46875\n",
      "[1501/4132]Epoch: 2/2 Loss: 2.2832984924316406 Pair Accuracy: 0.46875 Start Accuracy: 0.5 End Accuracy: 0.5\n",
      "[1601/4132]Epoch: 2/2 Loss: 2.4861834049224854 Pair Accuracy: 0.15625 Start Accuracy: 0.28125 End Accuracy: 0.3125\n",
      "[1701/4132]Epoch: 2/2 Loss: 3.152608871459961 Pair Accuracy: 0.125 Start Accuracy: 0.15625 End Accuracy: 0.25\n",
      "[1801/4132]Epoch: 2/2 Loss: 2.2585887908935547 Pair Accuracy: 0.15625 Start Accuracy: 0.25 End Accuracy: 0.5\n",
      "[1901/4132]Epoch: 2/2 Loss: 2.206153154373169 Pair Accuracy: 0.15625 Start Accuracy: 0.34375 End Accuracy: 0.40625\n",
      "[2001/4132]Epoch: 2/2 Loss: 2.2918548583984375 Pair Accuracy: 0.40625 Start Accuracy: 0.53125 End Accuracy: 0.53125\n",
      "[2101/4132]Epoch: 2/2 Loss: 1.5728933811187744 Pair Accuracy: 0.46875 Start Accuracy: 0.53125 End Accuracy: 0.65625\n",
      "[2201/4132]Epoch: 2/2 Loss: 2.459968328475952 Pair Accuracy: 0.34375 Start Accuracy: 0.375 End Accuracy: 0.59375\n",
      "[2301/4132]Epoch: 2/2 Loss: 2.5958609580993652 Pair Accuracy: 0.09375 Start Accuracy: 0.09375 End Accuracy: 0.46875\n",
      "[2401/4132]Epoch: 2/2 Loss: 3.4841582775115967 Pair Accuracy: 0.0625 Start Accuracy: 0.1875 End Accuracy: 0.15625\n",
      "[2501/4132]Epoch: 2/2 Loss: 2.6300110816955566 Pair Accuracy: 0.1875 Start Accuracy: 0.3125 End Accuracy: 0.375\n",
      "[2601/4132]Epoch: 2/2 Loss: 2.91294527053833 Pair Accuracy: 0.28125 Start Accuracy: 0.28125 End Accuracy: 0.5\n",
      "[2701/4132]Epoch: 2/2 Loss: 2.287256956100464 Pair Accuracy: 0.3125 Start Accuracy: 0.4375 End Accuracy: 0.46875\n",
      "[2801/4132]Epoch: 2/2 Loss: 2.5260441303253174 Pair Accuracy: 0.25 Start Accuracy: 0.34375 End Accuracy: 0.34375\n",
      "[2901/4132]Epoch: 2/2 Loss: 2.6312437057495117 Pair Accuracy: 0.25 Start Accuracy: 0.40625 End Accuracy: 0.46875\n",
      "[3001/4132]Epoch: 2/2 Loss: 2.251789093017578 Pair Accuracy: 0.1875 Start Accuracy: 0.25 End Accuracy: 0.53125\n",
      "[3101/4132]Epoch: 2/2 Loss: 2.3557376861572266 Pair Accuracy: 0.40625 Start Accuracy: 0.4375 End Accuracy: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3201/4132]Epoch: 2/2 Loss: 3.0476303100585938 Pair Accuracy: 0.15625 Start Accuracy: 0.1875 End Accuracy: 0.3125\n",
      "[3301/4132]Epoch: 2/2 Loss: 2.7580151557922363 Pair Accuracy: 0.3125 Start Accuracy: 0.375 End Accuracy: 0.59375\n",
      "[3401/4132]Epoch: 2/2 Loss: 3.816824436187744 Pair Accuracy: 0.0625 Start Accuracy: 0.09375 End Accuracy: 0.25\n",
      "[3501/4132]Epoch: 2/2 Loss: 3.6575026512145996 Pair Accuracy: 0.0 Start Accuracy: 0.0625 End Accuracy: 0.15625\n",
      "[3601/4132]Epoch: 2/2 Loss: 2.5974173545837402 Pair Accuracy: 0.125 Start Accuracy: 0.25 End Accuracy: 0.21875\n",
      "[3701/4132]Epoch: 2/2 Loss: 2.0401740074157715 Pair Accuracy: 0.40625 Start Accuracy: 0.59375 End Accuracy: 0.46875\n",
      "[3801/4132]Epoch: 2/2 Loss: 2.9091100692749023 Pair Accuracy: 0.125 Start Accuracy: 0.34375 End Accuracy: 0.1875\n",
      "[3901/4132]Epoch: 2/2 Loss: 2.093696355819702 Pair Accuracy: 0.15625 Start Accuracy: 0.5 End Accuracy: 0.3125\n",
      "[4001/4132]Epoch: 2/2 Loss: 3.4725441932678223 Pair Accuracy: 0.03125 Start Accuracy: 0.125 End Accuracy: 0.125\n",
      "[4101/4132]Epoch: 2/2 Loss: 2.6210825443267822 Pair Accuracy: 0.09375 Start Accuracy: 0.1875 End Accuracy: 0.375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transformer4QA(\n",
       "  (backbone): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (QA): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(modelA, 2, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA.load_state_dict(torch.load(\"albert.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 11873/11873 [00:17<00:00, 671.21it/s]\n",
      "add example index and unique id: 100%|██████████| 11873/11873 [00:00<00:00, 625104.77it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset, test_features, test_examples = create_train_dataset(test_df, tokenizer)\n",
    "\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def predict(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        to_return = []\n",
    "        for idx, batch in enumerate(tqdm(test_dataloader)):\n",
    "            _ ,start_logits, end_logits = model(batch,device=device)      \n",
    "            \n",
    "            start_pred = torch.argmax(start_logits, dim=1).cpu()\n",
    "            end_pred = torch.argmax(end_logits, dim=1).cpu()\n",
    "            \n",
    "            for start, end in zip(start_pred, end_pred):\n",
    "                to_return.append((start.item(), end.item()))\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(results):\n",
    "    to_return = []\n",
    "    for res, feat, example in zip(results, test_features, test_examples):\n",
    "        if res[0] == 0 and res[1] == 0:\n",
    "            to_return.append('')\n",
    "        else:\n",
    "            tok_tokens = feat.tokens[res[0] : (res[1] + 1)]\n",
    "            if res[0] < min(feat.token_to_orig_map):\n",
    "                start = min(feat.token_to_orig_map)\n",
    "            elif res[0] > max(feat.token_to_orig_map):\n",
    "                start = max(feat.token_to_orig_map)\n",
    "            else:\n",
    "                start = res[0]\n",
    "                \n",
    "            if res[1] < min(feat.token_to_orig_map):\n",
    "                end = min(feat.token_to_orig_map)\n",
    "            elif res[1] > max(feat.token_to_orig_map):\n",
    "                end = max(feat.token_to_orig_map)\n",
    "            else:\n",
    "                end = res[1]\n",
    "            \n",
    "            orig_doc_start = feat.token_to_orig_map[start]\n",
    "            orig_doc_end = feat.token_to_orig_map[end]\n",
    "            orig_tokens = example.doc_tokens[orig_doc_start : (orig_doc_end + 1)]\n",
    "            tok_text = tokenizer.convert_tokens_to_string(tok_tokens)\n",
    "\n",
    "            tok_text = tok_text.strip()\n",
    "            tok_text = \" \".join(tok_text.split())\n",
    "            orig_text = \" \".join(orig_tokens)\n",
    "            final_text = get_final_text(tok_text, orig_text, True, True)\n",
    "\n",
    "            to_return.append(final_text)\n",
    "    \n",
    "    answers = {}\n",
    "    for text,row in zip(to_return, test_df.loc):\n",
    "        answers[row.id] = text\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb17c37b14dd4d66a697669dfd10976f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=384.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "my_preds = predict(modelA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_preds(my_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 5.558830961003959,\n",
      "  \"f1\": 8.6014493757091,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 0.18556005398110662,\n",
      "  \"HasAns_f1\": 6.279522341058474,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 10.916736753574432,\n",
      "  \"NoAns_f1\": 10.916736753574432,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# For the more representetive results we have taken script that squad owner's have written to check predictions\n",
    "dataset = test_sq.data\n",
    "preds = res\n",
    "na_probs = {k: 0.0 for k in preds}\n",
    "\n",
    "qid_to_has_ans = make_qid_to_has_ans(dataset) \n",
    "has_ans_qids = [k for k, v in qid_to_has_ans.items() if v]\n",
    "no_ans_qids = [k for k, v in qid_to_has_ans.items() if not v]\n",
    "exact_raw, f1_raw = get_raw_scores(dataset, preds)\n",
    "exact_thresh = apply_no_ans_threshold(exact_raw, na_probs, qid_to_has_ans,\n",
    "                                      1.0)\n",
    "f1_thresh = apply_no_ans_threshold(f1_raw, na_probs, qid_to_has_ans,\n",
    "                                   1.0)\n",
    "out_eval = make_eval_dict(exact_thresh, f1_thresh)\n",
    "if has_ans_qids:\n",
    "    has_ans_eval = make_eval_dict(exact_thresh, f1_thresh, qid_list=has_ans_qids)\n",
    "    merge_eval(out_eval, has_ans_eval, 'HasAns')\n",
    "if no_ans_qids:\n",
    "    no_ans_eval = make_eval_dict(exact_thresh, f1_thresh, qid_list=no_ans_qids)\n",
    "    merge_eval(out_eval, no_ans_eval, 'NoAns')\n",
    "print(json.dumps(out_eval, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Ctenophora (/tᵻˈnɒfərə/; singular ctenophore, /ˈtɛnəfɔːr/ or /ˈtiːnəfɔːr/; from the Greek κτείς kteis 'comb' and φέρω pherō 'carry'; commonly known as comb jellies) is a phylum of animals that live in marine waters worldwide. Their most distinctive feature is the ‘combs’ – groups of cilia which they use for swimming – they are the largest animals that swim by means of cilia. Adults of various species range from a few millimeters to 1.5 m (4 ft 11 in) in size. Like cnidarians, their bodies consist of a mass of jelly, with one layer of cells on the outside and another lining the internal cavity. In ctenophores, these layers are two cells deep, while those in cnidarians are only one cell deep. Some authors combined ctenophores and cnidarians in one phylum, Coelenterata, as both groups rely on water flow through the body cavity for both digestion and respiration. Increasing awareness of the differences persuaded more recent authors to classify them as separate phyla.\n",
      "\n",
      "Question:  How large can ctenophora grow?\n",
      "\n",
      "Answer:  1.5 m (4 ft 11 in)\n",
      "\n",
      "Predicted answer:  Ctenophora (/tᵻˈnɒfərə/; singular ctenophore, /ˈtɛnəfɔːr/ or /ˈtiːnəfɔːr/; from the Greek κτείς kteis 'comb' and φέρω pherō 'carry'; commonly known as comb jellies) is a phylum of animals that live in marine waters worldwide. Their most distinctive feature is the ‘combs’ – groups of cilia which they use for swimming – they are the largest animals that swim by means of cilia. Adults of various species range from a few millimeters to 1.5 m (4 ft 11 in) in size. Like cnidarians, their bodies consist of a mass of jelly, with one layer of cells on the outside and another lining the internal cavity. In ctenophores, these layers are\n",
      "\n",
      "//////////////////// \n",
      "\n",
      "Context:  Following the election of the UK Labour Party to government in 1997, the UK formally subscribed to the Agreement on Social Policy, which allowed it to be included with minor amendments as the Social Chapter of the 1997 Treaty of Amsterdam. The UK subsequently adopted the main legislation previously agreed under the Agreement on Social Policy, the 1994 Works Council Directive, which required workforce consultation in businesses, and the 1996 Parental Leave Directive. In the 10 years following the 1997 Treaty of Amsterdam and adoption of the Social Chapter the European Union has undertaken policy initiatives in various social policy areas, including labour and industry relations, equal opportunity, health and safety, public health, protection of children, the disabled and elderly, poverty, migrant workers, education, training and youth.\n",
      "\n",
      "Question:  Which directive mentioned was created in 1994?\n",
      "\n",
      "Answer:  Works Council Directive\n",
      "\n",
      "Predicted answer:  Following the election of the UK Labour Party to government in 1997, the UK formally subscribed to the Agreement on Social Policy, which allowed it to be included with minor amendments as the Social Chapter of the 1997 Treaty of Amsterdam. The UK subsequently adopted the main legislation previously agreed under the Agreement on Social Policy, the 1994 Works Council Directive, which required workforce consultation in businesses, and the 1996 Parental Leave Directive. In the 10 years following the 1997 Treaty of Amsterdam and adoption of the Social Chapter the European Union has undertaken policy initiatives in various social policy areas, including labour and industry relations, equal opportunity, health\n",
      "\n",
      "//////////////////// \n",
      "\n",
      "Context:  The Lobata have a pair of lobes, which are muscular, cuplike extensions of the body that project beyond the mouth. Their inconspicuous tentacles originate from the corners of the mouth, running in convoluted grooves and spreading out over the inner surface of the lobes (rather than trailing far behind, as in the Cydippida). Between the lobes on either side of the mouth, many species of lobates have four auricles, gelatinous projections edged with cilia that produce water currents that help direct microscopic prey toward the mouth. This combination of structures enables lobates to feed continuously on suspended planktonic prey.\n",
      "\n",
      "Question:  How many auricles do plankton have?\n",
      "\n",
      "Impossible to answer\n",
      "\n",
      "Predicted answer:  projections edged with\n",
      "\n",
      "//////////////////// \n",
      "\n",
      "Context:  Britain's imperialist ambitions can be seen as early as the sixteenth century. In 1599 the British East India Company was established and was chartered by Queen Elizabeth in the following year. With the establishment of trading posts in India, the British were able to maintain strength relative to others empires such as the Portuguese who already had set up trading posts in India. In 1767 political activity caused exploitation of the East India Company causing the plundering of the local economy, almost bringing the company into bankruptcy.\n",
      "\n",
      "Question:  When is the earliest Britain had an imperialist policy?\n",
      "\n",
      "Answer:  the sixteenth century\n",
      "\n",
      "Predicted answer:  Britain's imperialist ambitions can be seen as early as the sixteenth century. In 1599 the British East India Company was established and was chartered by Queen Elizabeth in the following year. With the establishment of trading posts in India, the British were able to maintain strength relative to others empires such as the Portuguese who already had set up trading posts in India. In 1767 political activity caused exploitation of the East India Company causing the plundering of the\n",
      "\n",
      "//////////////////// \n",
      "\n",
      "Context:  Deforestation is the conversion of forested areas to non-forested areas. The main sources of deforestation in the Amazon are human settlement and development of the land. Prior to the early 1960s, access to the forest's interior was highly restricted, and the forest remained basically intact. Farms established during the 1960s were based on crop cultivation and the slash and burn method. However, the colonists were unable to manage their fields and the crops because of the loss of soil fertility and weed invasion. The soils in the Amazon are productive for just a short period of time, so farmers are constantly moving to new areas and clearing more land. These farming practices led to deforestation and caused extensive environmental damage. Deforestation is considerable, and areas cleared of forest are visible to the naked eye from outer space.\n",
      "\n",
      "Question:  Areas of heavy forest are visible to the naked eye from where?\n",
      "\n",
      "Impossible to answer\n",
      "\n",
      "Predicted impossbile to answer\n",
      "\n",
      "//////////////////// \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    choice = np.random.choice(list(res))\n",
    "    row = test_df[test_df.id == choice].iloc[0]\n",
    "    print(\"Context: \", str(row.context))\n",
    "    print()\n",
    "    print(\"Question: \", str(row.content))\n",
    "    print()\n",
    "    if row.is_impossible:\n",
    "        print(\"Impossible to answer\")\n",
    "    else:\n",
    "        print(\"Answer: \", row.answer)\n",
    "    print()\n",
    "    if res[choice]:\n",
    "        print(\"Predicted answer: \", res[choice])\n",
    "    else:\n",
    "        print(\"Predicted impossbile to answer\")\n",
    "    print(\"\\n//////////////////// \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
