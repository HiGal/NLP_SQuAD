{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline we have build a simple transformer that just has as an input context+question and tries to predict an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper class to covert json to dataframe for easier batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squad:\n",
    "    def __init__(self, input_location):\n",
    "        self.location = input_location\n",
    "        file = open(input_location)\n",
    "        json_file = json.load(file)\n",
    "        # Save version and data\n",
    "        self.version = json_file['version']\n",
    "        self.data = json_file['data']\n",
    "        \n",
    "        df_builder = [] # We will store every row of dataframe here\n",
    "        for sample in self.data:\n",
    "            title = sample['title'] # Get title\n",
    "            paragraphs = sample['paragraphs']\n",
    "            \n",
    "            for paragraph in paragraphs:\n",
    "                context = paragraph['context'] # Get context, e.g. a paragraph\n",
    "                questions = paragraph['qas']\n",
    "                \n",
    "                for question in questions:\n",
    "                    q_id = question['id'] # Question id\n",
    "                    q_content = question['question'] # Question itself\n",
    "                    answers = question['answers'] # Possible answers\n",
    "                    is_impossible = question['is_impossible'] # If it is possible to answer\n",
    "                    \n",
    "                    # Build a row of dataframe\n",
    "                    qas = {\n",
    "                        'id':q_id,\n",
    "                        'wiki_title':title,\n",
    "                        'context':context,\n",
    "                        'content':q_content,\n",
    "                        'is_impossible':is_impossible\n",
    "                    }\n",
    "                    if is_impossible:\n",
    "                        qas['answer'] = \"\"\n",
    "                        qas['answer_start'] = 0\n",
    "                        qas['answer_end'] = 0\n",
    "                    else:\n",
    "                        answer = answers[0]\n",
    "                        qas['answer'] = answer['text']\n",
    "                        qas['answer_start'] = answer['answer_start']\n",
    "                        qas['answer_end'] = answer['answer_start']+len(answer['text'])\n",
    "                    df_builder.append(qas) \n",
    "        self.df = pd.DataFrame(df_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sq = Squad('./data/train-v2.0.json')\n",
    "test_sq = Squad('./data/dev-v2.0.json')\n",
    "train_df  = train_sq.df\n",
    "test_df  = test_sq.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import *\n",
    "from torchtext.data import *\n",
    "\n",
    "# Taken from here for easier work with dataframe and torchtext\n",
    "# https://gist.github.com/notnami/3c4d636f2b79e206b26acfe349f2657a\n",
    "class DataFrameExampleSet:\n",
    "    def __init__(self, df, fields):\n",
    "        self._df = df\n",
    "        self._fields = fields\n",
    "        self._fields_dict = {field_name: (field_name, field)\n",
    "                             for field_name, field in fields.items()\n",
    "                             if field is not None}\n",
    "\n",
    "    def __iter__(self):\n",
    "        for item in tqdm(self._df.itertuples(), total=len(self)):\n",
    "            example = Example.fromdict(item._asdict(), fields=self._fields_dict)\n",
    "            yield example\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._df)\n",
    "\n",
    "    def shuffle(self, random_state=None):\n",
    "        self._df = self._df.sample(frac=1.0, random_state=random_state)\n",
    "\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, df, fields, filter_pred=None):\n",
    "        examples = DataFrameExampleSet(df, fields)\n",
    "        super().__init__(examples, fields, filter_pred=filter_pred)\n",
    "\n",
    "\n",
    "class DataFrameBucketIterator(BucketIterator):\n",
    "    def data(self):\n",
    "        if isinstance(self.dataset.examples, DataFrameExampleSet):\n",
    "            if self.shuffle:\n",
    "                self.dataset.examples.shuffle()\n",
    "            dataset = self.dataset\n",
    "        else:\n",
    "            dataset = super().data()\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from typing import *\n",
    "from torchtext.data import *\n",
    "from tqdm.notebook import tqdm\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import dill\n",
    "load = True\n",
    "# TRG_LEN=15\n",
    "# CONTEXT_Q_LEN = 400\n",
    "\n",
    "if load:\n",
    "    with open(\"model/CONTEXT.Field\",\"rb\") as f:\n",
    "        CONTEXT=dill.load(f)\n",
    "    with open(\"model/QUESTION.Field\",\"rb\") as f:\n",
    "        QUESTION=dill.load(f)\n",
    "else:\n",
    "    # Init Fields \n",
    "    \n",
    "    # Here will be context and question\n",
    "    CONTEXT = torchtext.data.Field(tokenize = get_tokenizer(\"basic_english\"),\n",
    "                          init_token = '<sos>',\n",
    "                          eos_token = '<eos>',\n",
    "                          lower = False,\n",
    "                          batch_first = False)\n",
    "    # here the target \n",
    "    QUESTION = torchtext.data.Field(tokenize = get_tokenizer(\"basic_english\"), \n",
    "                         init_token = '<sos>',\n",
    "                         eos_token = '<eos>',\n",
    "                         lower = False,\n",
    "                         batch_first = False)\n",
    "\n",
    "START = torchtext.data.Field(sequential=False, is_target=True, use_vocab=False)\n",
    "END = torchtext.data.Field(sequential=False, is_target=True, use_vocab=False)\n",
    "# Will store id to later check correctness\n",
    "ID = torchtext.data.Field(is_target=True, sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataFrameDataset(train_df, fields={'context':CONTEXT,'content':QUESTION, 'id':ID,\n",
    "                                                   'answer_start':START, 'answer_end':END})\n",
    "test_dataset = DataFrameDataset(test_df, fields={'context':CONTEXT,'content':QUESTION, 'id':ID,\n",
    "                                                'answer_start':START, 'answer_end':END})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b95012701a4827b02c9def507866df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=130319.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if load:\n",
    "    pass\n",
    "else:\n",
    "    # Build vocabulary from our data, target will have the same vocab as context + questions\n",
    "    CONTEXT.build_vocab(train_dataset, min_freq=100)\n",
    "    QUESTION.build_vocab([''])\n",
    "    QUESTION.vocab = CONTEXT.vocab\n",
    "    \n",
    "    \n",
    "    with open(\"model/CONTEXT.Field\",\"wb+\")as f:\n",
    "        dill.dump(CONTEXT,f)\n",
    "    with open(\"model/QUESTION.Field\",\"wb+\")as f:\n",
    "        dill.dump(QUESTION,f)\n",
    "ID.build_vocab(list(train_df.id)+ list(test_df.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# Create iterators\n",
    "train_iterator, test_iterator = DataFrameBucketIterator.splits((train_dataset, test_dataset), \n",
    "                                    batch_size = batch_size,\n",
    "                                    device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineAttn(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BaselineAttn, self).__init__()\n",
    "        \n",
    "        self.linear_context = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_question = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.linear_combination = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, context, question):\n",
    "        lin_context = self.linear_context(context) # [1, batch, hidden_size]\n",
    "        lin_question = self.linear_question(question) # [question_seq_len, batch, hidden_size]\n",
    "        \n",
    "        combined = torch.tanh(lin_context + lin_question) # [question_seq_len, batch, hidden_size]\n",
    "        lin_combined = self.linear_combination(combined).squeeze(2) # [question_seq_len, batch]\n",
    "        \n",
    "        attn = torch.nn.functional.softmax(lin_combined, dim=0) # [question_seq_len, batch]\n",
    "        return attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, context_vocab, emb_size, hidden_size,\n",
    "                dropout=0.1):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        \n",
    "        self.context_emb = nn.Embedding(context_vocab, emb_size)\n",
    "        self.question_emb = nn.Embedding(context_vocab, emb_size)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.rnn_context = nn.GRU(emb_size, hidden_size)\n",
    "        self.rnn_question = nn.GRU(emb_size, hidden_size)\n",
    "        \n",
    "        self.attn = BaselineAttn(hidden_size)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size*2, 2)\n",
    "        \n",
    "        self._init_params()\n",
    "    \n",
    "    def forward(self, context, question):\n",
    "        context_embedded = self.dropout_1(self.context_emb(context)) # [context_seq_len, batch_size, emb_size]\n",
    "        question_embedded = self.dropout_2(self.question_emb(question)) # [question_seq_len, batch_size, emb_size]\n",
    "        \n",
    "        output_context, hidden_context = self.rnn_context(context_embedded) # [context_seq_len, batch_size, hidden_size]\n",
    "        output_question, hidden_question = self.rnn_question(question_embedded) # [question_seq_len, batch_size, hidden_size]\n",
    "        print(hidden_context.shape)\n",
    "        print(hidden_question.shape)\n",
    "        \n",
    "        res = torch.zeros([\n",
    "            output_context.shape[0],\n",
    "            output_context.shape[1],\n",
    "            output_context.shape[2] * 2\n",
    "        ]).to(device)\n",
    "        \n",
    "        for i in range(len(output_context)):\n",
    "            hp = output_context[i, ...]\n",
    "            attn = self.attn(hp, output_question)\n",
    "            attn_applied = torch.bmm(attn.transpose(0,1).unsqueeze(1), output_question.transpose(0,1)).squeeze(1)\n",
    "            res[i] = torch.cat([hp, attn_applied],dim=1)\n",
    "        \n",
    "        logits = self.fc_out(res)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "        \n",
    "        return start_logits, end_logits\n",
    "    \n",
    "    def _init_params(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                torch.nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vocab = len(CONTEXT.vocab)\n",
    "emb_size=256\n",
    "hidden_size=512\n",
    "\n",
    "model = BaselineModel(context_vocab, emb_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has a total of 8,723,971 of trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'Model has a total of {count_trainable_parameters(model):,} of trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=2e-5)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, loss_func):\n",
    "    \"\"\"\n",
    "    Runs training loop for whole dataset in iterator\n",
    "    \n",
    "    model - model to be trained\n",
    "    iterator - data loader from which we take source and target\n",
    "    optimizer - our optimizer\n",
    "    loss_func - function which will compute loss\n",
    "    return average loss\n",
    "    \"\"\"\n",
    "    model.train() # Switch to train\n",
    "    epoch_loss = [] # We will calculate cumulative loss\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        context = batch.context.to(device)\n",
    "        content = batch.content.to(device)\n",
    "        start_positions = batch.answer_start.to(device)\n",
    "        end_positions = batch.answer_end.to(device)\n",
    "        \n",
    "        start_logits, end_logits = model(context, content)\n",
    "        \n",
    "        start_logits, end_logits = start_logits.transpose(0,1), end_logits.transpose(0,1)\n",
    "        ignored_index = start_logits.size(1)\n",
    "        start_positions.clamp_(0, ignored_index)\n",
    "        end_positions.clamp_(0, ignored_index)\n",
    "\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(ignore_index=ignored_index)\n",
    "        \n",
    "        start_loss = loss_fct(start_logits, start_positions)\n",
    "        end_loss = loss_fct(end_logits, end_positions)\n",
    "        total_loss = (start_loss + end_loss) / 2\n",
    "    \n",
    "        writer.add_scalar(f'Loss/train Epoch {epoch}', total_loss, i)\n",
    "        \n",
    "        epoch_loss.append(total_loss.item())\n",
    "        \n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, loss_func):\n",
    "    \"\"\"\n",
    "    Runs an evaluation loop and returns average loss\n",
    "    \n",
    "    model - model to be evaluated\n",
    "    iterator - data loader with validation set\n",
    "    loss_func - function which will compute loss\n",
    "    returns average loss\n",
    "    \"\"\"\n",
    "    model.eval() # Switch to eval\n",
    "    epoch_loss = 0 # We will calculate cumulative loss\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        to_return = []\n",
    "        \n",
    "        for i, batch in enumerate(iterator):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            context = batch.context.to(device)\n",
    "            content = batch.content.to(device)\n",
    "            start_positions = batch.answer_start.to(device)\n",
    "            end_positions = batch.answer_end.to(device)\n",
    "\n",
    "            start_logits, end_logits = model(context, content)\n",
    "            \n",
    "            start_logits, end_logits = start_logits.transpose(0,1), end_logits.transpose(0,1)\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions.clamp_(0, ignored_index)\n",
    "            end_positions.clamp_(0, ignored_index)\n",
    "\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(ignore_index=ignored_index)\n",
    "\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "            \n",
    "            start_pred = start_logits.softmax(dim=1).topk(1, dim=1)[1].squeeze().cpu().detach().numpy()\n",
    "            end_pred = end_logits.softmax(dim=1).topk(1, dim=1)[1].squeeze().cpu().detach().numpy()\n",
    "            \n",
    "            to_return.append((start_pred, end_pred, batch.id))\n",
    "            epoch_loss += total_loss.item()\n",
    "\n",
    "            optimizer.step()\n",
    "    return epoch_loss / len(iterator), to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9222c964c5994cf2989fa9fe8e7fa002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=130319.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 512])\n",
      "torch.Size([1, 128, 512])\n",
      "torch.Size([1, 128, 512])\n",
      "torch.Size([1, 128, 512])\n",
      "torch.Size([1, 128, 512])\n",
      "torch.Size([1, 128, 512])\n",
      "torch.Size([1, 128, 512])\n",
      "torch.Size([1, 128, 512])\n",
      "torch.Size([1, 128, 512])\n",
      "torch.Size([1, 128, 512])\n",
      "torch.Size([1, 128, 512])\n",
      "torch.Size([1, 128, 512])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1fd35db81f1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0meval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-ccec77eafaf9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, loss_func)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mend_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mstart_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mstart_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b41d9842f663>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, context, question)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moutput_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0moutput_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         ]).to(device)\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy.random as random \n",
    "\n",
    "best_loss = float('inf')\n",
    "epochs = 4\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_iterator, optimizer, loss_func)\n",
    "    \n",
    "    eval_loss, preds = evaluate(model, test_iterator, loss_func)\n",
    "    \n",
    "    print(preds[0])\n",
    "    # save \"best\" model\n",
    "    if best_loss > eval_loss:\n",
    "        best_loss = eval_loss\n",
    "        torch.save(model.state_dict(), 'baseline.model')\n",
    "    print(f\"Epoch {epoch}. Train loss: {np.mean(train_loss)}. Eval loss: {eval_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_loss, preds = evaluate(model, test_iterator, loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten output\n",
    "predictions = []\n",
    "labels = []\n",
    "for i in preds:\n",
    "    for seq1,seq2, tgt in zip(i[0], i[1], i[2]):\n",
    "        predictions.append((seq1,seq2))\n",
    "        labels.append(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(predictions, labels, df):\n",
    "    # Transform our predictions\n",
    "    my_preds = {}\n",
    "\n",
    "    for pred, tgt in zip(predictions, labels):\n",
    "        start, end = pred\n",
    "        tg_id = ID.vocab.itos[tgt]\n",
    "        res = df[df.id == tg_id].context.values[0][start:end]\n",
    "        my_preds[ID.vocab.itos[tgt]] = res\n",
    "    return my_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_preds = get_preds(predictions, labels, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_answers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For the more representetive results we have taken script that squad owner's have written to check predictions\n",
    "\n",
    "dataset = test_sq.data\n",
    "preds = my_preds\n",
    "na_probs = {k: 0.0 for k in preds}\n",
    "\n",
    "qid_to_has_ans = make_qid_to_has_ans(dataset) \n",
    "has_ans_qids = [k for k, v in qid_to_has_ans.items() if v]\n",
    "no_ans_qids = [k for k, v in qid_to_has_ans.items() if not v]\n",
    "exact_raw, f1_raw = get_raw_scores(dataset, preds)\n",
    "exact_thresh = apply_no_ans_threshold(exact_raw, na_probs, qid_to_has_ans,\n",
    "                                      1.0)\n",
    "f1_thresh = apply_no_ans_threshold(f1_raw, na_probs, qid_to_has_ans,\n",
    "                                   1.0)\n",
    "out_eval = make_eval_dict(exact_thresh, f1_thresh)\n",
    "if has_ans_qids:\n",
    "    has_ans_eval = make_eval_dict(exact_thresh, f1_thresh, qid_list=has_ans_qids)\n",
    "    merge_eval(out_eval, has_ans_eval, 'HasAns')\n",
    "if no_ans_qids:\n",
    "    no_ans_eval = make_eval_dict(exact_thresh, f1_thresh, qid_list=no_ans_qids)\n",
    "    merge_eval(out_eval, no_ans_eval, 'NoAns')\n",
    "print(json.dumps(out_eval, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some samples of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    choice = np.random.choice(list(my_preds))\n",
    "    row = test_df[test_df.id == choice].iloc[0]\n",
    "    print(\"Context: \", str(row.context))\n",
    "    print()\n",
    "    print(\"Question: \", str(row.content))\n",
    "    print()\n",
    "    if row.is_impossible:\n",
    "        print(\"Impossible to answer\")\n",
    "    else:\n",
    "        print(\"Answer: \", row.answer)\n",
    "    print()\n",
    "    if my_preds[choice]:\n",
    "        print(\"Predicted answer: \", my_preds[choice])\n",
    "    else:\n",
    "        print(\"Predicted impossbile to answer\")\n",
    "    print(\"\\n//////////////////// \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
